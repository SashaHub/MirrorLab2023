{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "mount_file_id": "1joZc_V8Zzk_YDw1Q_my99LTsNMCfFdf0",
      "authorship_tag": "ABX9TyMjkBKEIzfN0//F1+cIVpMb"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Установка библиотек"
      ],
      "metadata": {
        "id": "v7O4MBIQvwCe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Установка необходимых библиотек\n",
        "!pip install gensim transformers torch scikit-learn nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VR-Oab7EvvLm",
        "outputId": "f6ad2499-fe1b-4485-f981-b1a531298776"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.3)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (7.0.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Импорт"
      ],
      "metadata": {
        "id": "2zQL4U34v1NH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "import nltk\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0X3XqCv_v48D",
        "outputId": "1fe46138-dacd-4068-a7de-162fc63b112a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def flatten_to_text(value):\n",
        "    \"\"\"\n",
        "    Преобразует значение в текст:\n",
        "    - Массивы: объединяются в строку через пробел.\n",
        "    - Словари: значения объединяются в строку через пробел.\n",
        "    - Другие типы: конвертируются в строку напрямую.\n",
        "    - Пропущенные значения заменяются на пустую строку.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if isinstance(value, list):  # Проверка для списков\n",
        "            return \" \".join(map(str, value))\n",
        "        elif isinstance(value, dict):  # Проверка для словарей\n",
        "            return \" \".join(map(str, value.values()))\n",
        "        elif pd.isnull(value):  # Пропущенные значения\n",
        "            return \"\"\n",
        "        else:\n",
        "            return str(value)  # Конвертация остальных типов\n",
        "    except Exception as e:\n",
        "        print(f\"Ошибка при обработке значения: {value}, ошибка: {e}\")\n",
        "        return \"\"  # Возврат пустой строки при ошибке\n",
        "\n",
        "def preprocess_dataframe(data, text_columns):\n",
        "    \"\"\"\n",
        "    Преобразует указанные колонки в датафрейме:\n",
        "    - Преобразует массивы, словари и другие значения в строки.\n",
        "    - Объединяет текстовые поля в один столбец.\n",
        "    \"\"\"\n",
        "    for col in text_columns:\n",
        "        data[col] = data[col].apply(flatten_to_text)  # Преобразование каждого значения\n",
        "\n",
        "    # Создаем общий текстовый столбец\n",
        "    data['text'] = data[text_columns].apply(lambda row: ' '.join(row.values.astype(str)), axis=1)\n",
        "    return data"
      ],
      "metadata": {
        "id": "TSZktiawxPeo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "    Простая функция для препроцессинга текста:\n",
        "    - Приводит текст к нижнему регистру.\n",
        "    - Удаляет пунктуацию, слэши, и прочий \"мусор\".\n",
        "    - Оставляет только буквы и пробелы.\n",
        "\n",
        "    Args:\n",
        "        text (str): Исходный текст.\n",
        "\n",
        "    Returns:\n",
        "        str: Очищенный текст.\n",
        "    \"\"\"\n",
        "    # Приведение к нижнему регистру\n",
        "    text = text.lower()\n",
        "    # Удаление нежелательных символов (оставляем только буквы и пробелы)\n",
        "    text = re.sub(r'[^а-яА-ЯёЁa-zA-Z\\s]', '', text)\n",
        "    # Замена множественных пробелов на один\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "GFrivz6207Ft"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Загрузка и обработка данных"
      ],
      "metadata": {
        "id": "tlSICXOWv4fZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/MyDrive/DocsNew1/epic_records_with_target.parquet'\n",
        "data = pd.read_parquet(file_path)\n",
        "use_columns = ['gender', 'amnez_life', 'amnez_disease', 'condition',\n",
        "       'ward_table', 'full_wards', 'complication_of_main_disease_desc',\n",
        "       'main_disease_desc', 'secondary_disease_desc']"
      ],
      "metadata": {
        "id": "krTuEXScwKbO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = preprocess_dataframe(data, use_columns)"
      ],
      "metadata": {
        "id": "TX6r-oTLwdHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Лемматизация и стемминг"
      ],
      "metadata": {
        "id": "bcZLvTtPx1I1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.data.path.append(\"/root/nltk_data\")"
      ],
      "metadata": {
        "id": "v7BcWpczzg2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('russian'))\n",
        "stemmer = SnowballStemmer(\"russian\")\n",
        "\n",
        "def preprocess_text(text):\n",
        "    tokens = word_tokenize(text, language=\"russian\")\n",
        "    tokens = [stemmer.stem(word) for word in tokens if word.isalpha() and word not in stop_words]\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "# Применяем препроцессинг (данные для TF-IDF и модели без embeddings можно оставить с обработкой)\n",
        "data['processed_text'] = data['text'].apply(preprocess_text)"
      ],
      "metadata": {
        "id": "SKZ0OQuLx0cB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['processed_text_simple'] = data['text'].apply(clean_text)"
      ],
      "metadata": {
        "id": "l04iJyF20-QM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.to_parquet('/content/drive/MyDrive/DocsNew1/preprocessed_records.parquet')"
      ],
      "metadata": {
        "id": "btutjOXE3JrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Обучение собственного word embedding на данных"
      ],
      "metadata": {
        "id": "8t0kS3S61NCH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Токенизация текстов для обучения word2vec\n",
        "tokenized_texts = [word_tokenize(text, language=\"russian\") for text in data['text']]"
      ],
      "metadata": {
        "id": "1p7o851S1IxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Инициализация и обучение Word2Vec\n",
        "w2v_model = Word2Vec(\n",
        "    sentences=tokenized_texts,  # Тексты в виде токенов\n",
        "    vector_size=100,            # Размер вектора embeddings\n",
        "    window=5,                   # Окно для соседей\n",
        "    min_count=10,               # Минимальное количество вхождений слова\n",
        "    workers=2,                  # Число потоков\n",
        "    sg=1                        # Используем Skip-gram\n",
        ")"
      ],
      "metadata": {
        "id": "vrze-HQ31Qn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Сохранение обученной модели\n",
        "w2v_model_path = \"/content/drive/MyDrive/DocsNew1/word2vec_custom.model\"\n",
        "w2v_model.save(w2v_model_path)\n",
        "print(\"Обученная модель word embeddings сохранена по пути:\", w2v_model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-zxdMcj1Wn1",
        "outputId": "a3caa5b3-f1b8-4712-c477-ac572026b778"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Обученная модель word embeddings сохранена по пути: /content/drive/MyDrive/DocsNew1/word2vec_custom.model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Пример использования собственного embeddings\n",
        "print(\"Пример embedding для слова 'инфаркт':\", w2v_model.wv['инфаркт'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzYp9bcv1Yt7",
        "outputId": "99efbc9a-385f-4c04-f47b-a16bed1c052b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Пример embedding для слова 'инфаркт': [ 0.29276365  0.6517586   0.5328845   0.73116666 -0.8496222  -0.636645\n",
            "  0.6585501   1.1890719  -0.79563886 -0.2130396  -0.42085025  0.15055671\n",
            "  0.07983494  0.31640658 -0.5890132   0.2721545   0.14484827 -0.5062335\n",
            " -0.23533274 -0.57325673  0.2820768   0.44494748  0.845124   -0.20620432\n",
            " -0.6613513  -0.32934397  0.24691     0.38782993 -0.50931334  0.29559615\n",
            "  0.84071743 -0.28958678 -0.27046475 -0.52372414  0.05379103  0.6286116\n",
            "  0.65153503 -0.80114216 -0.08808368 -1.1112344   1.2720308  -0.12672056\n",
            " -0.36405873  0.21855429  0.5761397   0.9261662  -0.20644742  0.27033344\n",
            " -0.30193034  0.8543009   0.504435   -0.8382857   0.00977375 -0.65603644\n",
            " -0.44226336 -0.00469937  0.7426868   0.22981463 -0.01551979  0.7230486\n",
            " -0.15901366 -1.0127788   0.9339757  -0.8905167  -0.7562497  -0.4298161\n",
            "  0.26092336  0.733011   -0.59222364  0.96409667  0.38321874 -0.4533126\n",
            "  1.1089891   0.48428282  0.13257563 -0.16951585  0.2496799  -0.5567076\n",
            " -0.01357115 -0.2820412   0.3497293   0.6562468  -0.55391735 -0.02178465\n",
            " -0.41447487 -0.5511931   0.21088259 -0.41327652 -0.2591817   0.19980976\n",
            " -0.29223067  0.62955976  0.49362403  0.44736508  0.24625517  0.61757976\n",
            "  0.68482053 -0.7540835   0.35114363 -0.8857855 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Загрузка предобученных word embeddings (например, FastText или Word2Vec)"
      ],
      "metadata": {
        "id": "C5eIBLSNzxW6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import KeyedVectors\n",
        "\n",
        "# Укажите путь к предобученной модели word embeddings\n",
        "embedding_model_path = \"/content/drive/MyDrive/DocsNew1/word2vec_custom.model\"\n",
        "try:\n",
        "    word_vectors = KeyedVectors.load(embedding_model_path)\n",
        "    print(\"Предобученные word embeddings успешно загружены!\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Ошибка загрузки предобученной модели! Проверьте путь.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O039e2OkzB_c",
        "outputId": "ab7f716e-93a0-49c3-8c74-a7546152fa36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Предобученные word embeddings успешно загружены!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Преобразование текста с использованием TF-IDF"
      ],
      "metadata": {
        "id": "n2bhSfnG1teT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_vectorizer = TfidfVectorizer(max_features=500)\n",
        "tfidf_features = tfidf_vectorizer.fit_transform(data['processed_text']).toarray()\n",
        "\n",
        "# Разделение на обучающую и валидационную выборки\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    data['processed_text'], data['target'], test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "COVWoS_I1wUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Использование word embeddings и модели трансформера"
      ],
      "metadata": {
        "id": "QLk875mH118C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_parquet('/content/drive/MyDrive/DocsNew1/preprocessed_records.parquet')"
      ],
      "metadata": {
        "id": "cigciFuHwN4l"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Разделение на обучающую и валидационную выборки\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    data['processed_text_simple'], data['target'], test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "n2k68UVnv5Ct"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Инициализация токенизатора и модели трансформера\n",
        "model_name = 'alexyalunin/RuBioBERT'\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2)"
      ],
      "metadata": {
        "id": "WEI8RG_Q15AR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d724fc25-bafa-4bce-efe1-f77211af3b7e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at alexyalunin/RuBioBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.bert.parameters():\n",
        "    param.requires_grad = False\n",
        "#Определение класса датасета\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len=512):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts.iloc[idx]\n",
        "        label = self.labels.iloc[idx]\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            return_token_type_ids=False,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "        )\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': torch.tensor(label, dtype=torch.long)\n",
        "        }"
      ],
      "metadata": {
        "id": "GxlZIqbE186o"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Создание датасетов\n",
        "train_dataset = TextDataset(train_texts, train_labels, tokenizer)\n",
        "val_dataset = TextDataset(val_texts, val_labels, tokenizer)"
      ],
      "metadata": {
        "id": "5Dh4eWXl17Ty"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Параметры обучения"
      ],
      "metadata": {
        "id": "wDAUDMoL2DgZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=50,\n",
        "    per_device_train_batch_size=64,\n",
        "    per_device_eval_batch_size=512,\n",
        "    learning_rate=1e-3,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=13,\n",
        "    evaluation_strategy='epoch',\n",
        "    save_strategy='epoch',\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model='eval_loss',\n",
        ")"
      ],
      "metadata": {
        "id": "XVvkwBZL2Ehk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62855175-f6e5-4d76-a2c8-c33aa4c18a99"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = torch.argmax(torch.tensor(logits), dim=-1)\n",
        "    acc = accuracy_score(labels, predictions)\n",
        "    roc_auc = roc_auc_score(labels, logits[:, 1])\n",
        "    return {'accuracy': acc, 'roc_auc': roc_auc}"
      ],
      "metadata": {
        "id": "RyT7vdKa2GUv"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Тренировка модели трансформера"
      ],
      "metadata": {
        "id": "AExoZqcI2Jji"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "id": "1NuQf_Xs2H63"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "0bIdvoKE2NcF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dd76382c-b211-48fc-d259-7243c751a023"
      },
      "execution_count": 31,
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='521' max='650' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [521/650 38:37 < 09:35, 0.22 it/s, Epoch 40/50]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Roc Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.678600</td>\n",
              "      <td>0.681775</td>\n",
              "      <td>0.547739</td>\n",
              "      <td>0.628571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.658700</td>\n",
              "      <td>0.668000</td>\n",
              "      <td>0.613065</td>\n",
              "      <td>0.624417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.644900</td>\n",
              "      <td>0.665685</td>\n",
              "      <td>0.613065</td>\n",
              "      <td>0.628166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.630800</td>\n",
              "      <td>0.663865</td>\n",
              "      <td>0.613065</td>\n",
              "      <td>0.631307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.624800</td>\n",
              "      <td>0.664629</td>\n",
              "      <td>0.613065</td>\n",
              "      <td>0.638804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.620600</td>\n",
              "      <td>0.662817</td>\n",
              "      <td>0.603015</td>\n",
              "      <td>0.644681</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.622100</td>\n",
              "      <td>0.670263</td>\n",
              "      <td>0.623116</td>\n",
              "      <td>0.647720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.620300</td>\n",
              "      <td>0.666841</td>\n",
              "      <td>0.608040</td>\n",
              "      <td>0.650051</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.624700</td>\n",
              "      <td>0.662564</td>\n",
              "      <td>0.608040</td>\n",
              "      <td>0.650963</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.613400</td>\n",
              "      <td>0.659566</td>\n",
              "      <td>0.618090</td>\n",
              "      <td>0.655117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.621200</td>\n",
              "      <td>0.664817</td>\n",
              "      <td>0.608040</td>\n",
              "      <td>0.659068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.616800</td>\n",
              "      <td>0.657235</td>\n",
              "      <td>0.618090</td>\n",
              "      <td>0.661601</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.605900</td>\n",
              "      <td>0.656766</td>\n",
              "      <td>0.613065</td>\n",
              "      <td>0.664032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.613000</td>\n",
              "      <td>0.657825</td>\n",
              "      <td>0.618090</td>\n",
              "      <td>0.666363</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.615400</td>\n",
              "      <td>0.654676</td>\n",
              "      <td>0.623116</td>\n",
              "      <td>0.668997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.596900</td>\n",
              "      <td>0.653403</td>\n",
              "      <td>0.623116</td>\n",
              "      <td>0.669504</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.614800</td>\n",
              "      <td>0.655740</td>\n",
              "      <td>0.623116</td>\n",
              "      <td>0.671935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.606100</td>\n",
              "      <td>0.651890</td>\n",
              "      <td>0.623116</td>\n",
              "      <td>0.672543</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.608000</td>\n",
              "      <td>0.650838</td>\n",
              "      <td>0.623116</td>\n",
              "      <td>0.672948</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.611500</td>\n",
              "      <td>0.653252</td>\n",
              "      <td>0.623116</td>\n",
              "      <td>0.674063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.601000</td>\n",
              "      <td>0.651536</td>\n",
              "      <td>0.628141</td>\n",
              "      <td>0.674975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.609900</td>\n",
              "      <td>0.651449</td>\n",
              "      <td>0.628141</td>\n",
              "      <td>0.675684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.597200</td>\n",
              "      <td>0.648688</td>\n",
              "      <td>0.623116</td>\n",
              "      <td>0.676089</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.599500</td>\n",
              "      <td>0.648820</td>\n",
              "      <td>0.623116</td>\n",
              "      <td>0.676292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.603600</td>\n",
              "      <td>0.649136</td>\n",
              "      <td>0.623116</td>\n",
              "      <td>0.677001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.598300</td>\n",
              "      <td>0.648966</td>\n",
              "      <td>0.623116</td>\n",
              "      <td>0.676190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.608700</td>\n",
              "      <td>0.648253</td>\n",
              "      <td>0.623116</td>\n",
              "      <td>0.677710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.599300</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>0.623116</td>\n",
              "      <td>0.678116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.602500</td>\n",
              "      <td>0.646846</td>\n",
              "      <td>0.623116</td>\n",
              "      <td>0.680243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.595400</td>\n",
              "      <td>0.646123</td>\n",
              "      <td>0.633166</td>\n",
              "      <td>0.680142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.599600</td>\n",
              "      <td>0.647905</td>\n",
              "      <td>0.628141</td>\n",
              "      <td>0.680648</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.601800</td>\n",
              "      <td>0.646105</td>\n",
              "      <td>0.633166</td>\n",
              "      <td>0.681054</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.594000</td>\n",
              "      <td>0.645890</td>\n",
              "      <td>0.623116</td>\n",
              "      <td>0.680750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.599200</td>\n",
              "      <td>0.645965</td>\n",
              "      <td>0.623116</td>\n",
              "      <td>0.681155</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.603600</td>\n",
              "      <td>0.647184</td>\n",
              "      <td>0.633166</td>\n",
              "      <td>0.682168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.594800</td>\n",
              "      <td>0.647356</td>\n",
              "      <td>0.623116</td>\n",
              "      <td>0.681459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.596300</td>\n",
              "      <td>0.645033</td>\n",
              "      <td>0.633166</td>\n",
              "      <td>0.682371</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.603400</td>\n",
              "      <td>0.645196</td>\n",
              "      <td>0.628141</td>\n",
              "      <td>0.682371</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.607900</td>\n",
              "      <td>0.644870</td>\n",
              "      <td>0.623116</td>\n",
              "      <td>0.682573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.601600</td>\n",
              "      <td>0.644508</td>\n",
              "      <td>0.633166</td>\n",
              "      <td>0.682675</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='650' max='650' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [650/650 48:33, Epoch 50/50]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Roc Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.678600</td>\n",
              "      <td>0.681775</td>\n",
              "      <td>0.547739</td>\n",
              "      <td>0.628571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.658700</td>\n",
              "      <td>0.668000</td>\n",
              "      <td>0.613065</td>\n",
              "      <td>0.624417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.644900</td>\n",
              "      <td>0.665685</td>\n",
              "      <td>0.613065</td>\n",
              "      <td>0.628166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.630800</td>\n",
              "      <td>0.663865</td>\n",
              "      <td>0.613065</td>\n",
              "      <td>0.631307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.624800</td>\n",
              "      <td>0.664629</td>\n",
              "      <td>0.613065</td>\n",
              "      <td>0.638804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.620600</td>\n",
              "      <td>0.662817</td>\n",
              "      <td>0.603015</td>\n",
              "      <td>0.644681</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.622100</td>\n",
              "      <td>0.670263</td>\n",
              "      <td>0.623116</td>\n",
              "      <td>0.647720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.620300</td>\n",
              "      <td>0.666841</td>\n",
              "      <td>0.608040</td>\n",
              "      <td>0.650051</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.624700</td>\n",
              "      <td>0.662564</td>\n",
              "      <td>0.608040</td>\n",
              "      <td>0.650963</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.613400</td>\n",
              "      <td>0.659566</td>\n",
              "      <td>0.618090</td>\n",
              "      <td>0.655117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.621200</td>\n",
              "      <td>0.664817</td>\n",
              "      <td>0.608040</td>\n",
              "      <td>0.659068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.616800</td>\n",
              "      <td>0.657235</td>\n",
              "      <td>0.618090</td>\n",
              "      <td>0.661601</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.605900</td>\n",
              "      <td>0.656766</td>\n",
              "      <td>0.613065</td>\n",
              "      <td>0.664032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.613000</td>\n",
              "      <td>0.657825</td>\n",
              "      <td>0.618090</td>\n",
              "      <td>0.666363</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.615400</td>\n",
              "      <td>0.654676</td>\n",
              "      <td>0.623116</td>\n",
              "      <td>0.668997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.596900</td>\n",
              "      <td>0.653403</td>\n",
              "      <td>0.623116</td>\n",
              "      <td>0.669504</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.614800</td>\n",
              "      <td>0.655740</td>\n",
              "      <td>0.623116</td>\n",
              "      <td>0.671935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.606100</td>\n",
              "      <td>0.651890</td>\n",
              "      <td>0.623116</td>\n",
              "      <td>0.672543</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.608000</td>\n",
              "      <td>0.650838</td>\n",
              "      <td>0.623116</td>\n",
              "      <td>0.672948</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.611500</td>\n",
              "      <td>0.653252</td>\n",
              "      <td>0.623116</td>\n",
              "      <td>0.674063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.601000</td>\n",
              "      <td>0.651536</td>\n",
              "      <td>0.628141</td>\n",
              "      <td>0.674975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.609900</td>\n",
              "      <td>0.651449</td>\n",
              "      <td>0.628141</td>\n",
              "      <td>0.675684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.597200</td>\n",
              "      <td>0.648688</td>\n",
              "      <td>0.623116</td>\n",
              "      <td>0.676089</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.599500</td>\n",
              "      <td>0.648820</td>\n",
              "      <td>0.623116</td>\n",
              "      <td>0.676292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.603600</td>\n",
              "      <td>0.649136</td>\n",
              "      <td>0.623116</td>\n",
              "      <td>0.677001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.598300</td>\n",
              "      <td>0.648966</td>\n",
              "      <td>0.623116</td>\n",
              "      <td>0.676190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.608700</td>\n",
              "      <td>0.648253</td>\n",
              "      <td>0.623116</td>\n",
              "      <td>0.677710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.599300</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>0.623116</td>\n",
              "      <td>0.678116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.602500</td>\n",
              "      <td>0.646846</td>\n",
              "      <td>0.623116</td>\n",
              "      <td>0.680243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.595400</td>\n",
              "      <td>0.646123</td>\n",
              "      <td>0.633166</td>\n",
              "      <td>0.680142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.599600</td>\n",
              "      <td>0.647905</td>\n",
              "      <td>0.628141</td>\n",
              "      <td>0.680648</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.601800</td>\n",
              "      <td>0.646105</td>\n",
              "      <td>0.633166</td>\n",
              "      <td>0.681054</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.594000</td>\n",
              "      <td>0.645890</td>\n",
              "      <td>0.623116</td>\n",
              "      <td>0.680750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.599200</td>\n",
              "      <td>0.645965</td>\n",
              "      <td>0.623116</td>\n",
              "      <td>0.681155</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.603600</td>\n",
              "      <td>0.647184</td>\n",
              "      <td>0.633166</td>\n",
              "      <td>0.682168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.594800</td>\n",
              "      <td>0.647356</td>\n",
              "      <td>0.623116</td>\n",
              "      <td>0.681459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.596300</td>\n",
              "      <td>0.645033</td>\n",
              "      <td>0.633166</td>\n",
              "      <td>0.682371</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.603400</td>\n",
              "      <td>0.645196</td>\n",
              "      <td>0.628141</td>\n",
              "      <td>0.682371</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.607900</td>\n",
              "      <td>0.644870</td>\n",
              "      <td>0.623116</td>\n",
              "      <td>0.682573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.601600</td>\n",
              "      <td>0.644508</td>\n",
              "      <td>0.633166</td>\n",
              "      <td>0.682675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.602700</td>\n",
              "      <td>0.644863</td>\n",
              "      <td>0.623116</td>\n",
              "      <td>0.683384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.590900</td>\n",
              "      <td>0.644167</td>\n",
              "      <td>0.638191</td>\n",
              "      <td>0.683080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.604100</td>\n",
              "      <td>0.644565</td>\n",
              "      <td>0.623116</td>\n",
              "      <td>0.683181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.595200</td>\n",
              "      <td>0.643786</td>\n",
              "      <td>0.638191</td>\n",
              "      <td>0.683587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.603100</td>\n",
              "      <td>0.643752</td>\n",
              "      <td>0.633166</td>\n",
              "      <td>0.683384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.602100</td>\n",
              "      <td>0.643734</td>\n",
              "      <td>0.638191</td>\n",
              "      <td>0.683485</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.596900</td>\n",
              "      <td>0.643779</td>\n",
              "      <td>0.638191</td>\n",
              "      <td>0.683384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.597700</td>\n",
              "      <td>0.643697</td>\n",
              "      <td>0.638191</td>\n",
              "      <td>0.683384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.599500</td>\n",
              "      <td>0.643693</td>\n",
              "      <td>0.638191</td>\n",
              "      <td>0.683283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.596800</td>\n",
              "      <td>0.643726</td>\n",
              "      <td>0.633166</td>\n",
              "      <td>0.683283</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=650, training_loss=0.6091061012561505, metrics={'train_runtime': 2921.1399, 'train_samples_per_second': 13.556, 'train_steps_per_second': 0.223, 'total_flos': 1.0419197792256e+16, 'train_loss': 0.6091061012561505, 'epoch': 50.0})"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Сохранение обученной модели\n",
        "model.save_pretrained('/content/drive/MyDrive/DocsNew1/rubioBERT_finetuned')\n",
        "tokenizer.save_pretrained('/content/drive/MyDrive/DocsNew1/rubioBERT_finetuned_tokenizer')"
      ],
      "metadata": {
        "id": "QKnWbbTq2QcH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9d08c36-81cc-4a50-9e51-9f389467db75"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/DocsNew1/rubioBERT_finetuned_tokenizer/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/DocsNew1/rubioBERT_finetuned_tokenizer/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/DocsNew1/rubioBERT_finetuned_tokenizer/vocab.txt',\n",
              " '/content/drive/MyDrive/DocsNew1/rubioBERT_finetuned_tokenizer/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    }
  ]
}